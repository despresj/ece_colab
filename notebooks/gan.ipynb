{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1648841258917,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"hrpAj7PfN8d6","outputId":"360d8be0-41fe-4e05-81bf-30e49508900a"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-61987d96-15d2-7202-6c40-63e37fe357fc)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3570,"status":"ok","timestamp":1648841262484,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"wHi2BE1wNG3x"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18919,"status":"ok","timestamp":1648841281400,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"vc-vcG2_X-L3","outputId":"e8a40d67-d37c-4380-af9a-27697382fe32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  proj_dir = \"/content/drive/MyDrive/ece884_project/\"\n","else:\n","  proj_dir = \"../\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1365,"status":"ok","timestamp":1648841282761,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"pl_1AszIWuCr"},"outputs":[],"source":["df = pd.read_csv(f\"{proj_dir}data_clean/clean.csv\")\n","column_names = df.columns\n","df = df.to_numpy()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648841282762,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"EvV-bfce2s7V"},"outputs":[],"source":["from sklearn import preprocessing\n","scaler = preprocessing.StandardScaler().fit(df) # dont forget we have to transfer them back\n","df = scaler.transform(df)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2536,"status":"ok","timestamp":1648841285296,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"zPO14qCxNZQY"},"outputs":[],"source":["\n","generator = keras.models.Sequential([\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(200, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(400, activation=\"selu\"),\n","\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(400, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(200, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(100, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(98, activation=\"sigmoid\")\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648841285297,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"_LyRiRyuPZ1P"},"outputs":[],"source":["\n","discriminator = keras.models.Sequential([\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(200, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(400, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","\n","    keras.layers.Dense(300, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(200, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(100, activation=\"selu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1, activation=\"sigmoid\")\n","])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648841285297,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"r873giWoO9wU"},"outputs":[],"source":["gan = keras.models.Sequential([generator, discriminator])\n","\n","discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n","discriminator.trainable = False\n","gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648841285298,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"ces0DpqvNlUc"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648841285298,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"6v0D4WDFO_Da"},"outputs":[],"source":["def train_gan(\n","    gan, dataset, n_epochs=100, iterations=1000, n_noise=20000\n","):\n","\n","    \"\"\"\n","    Inputs: \n","\n","    gan, this is a keras gan object made by combining two neural nets and\n","    restricting the trainability of one of them.\n","\n","    dataset, this takes in regular tabular data. now this is training rowwise\n","    however i may change this to matrix wise like a picture.\n","\n","    n_epochs, numper of times the gans go though training iterations\n","\n","    iterations, number of times in gan iteraton loop, \n","    it would be a good idea to reduct this after the warmup period\n","\n","    n_noise, this is the size of fake data generated\n","\n","    \n","    Output:\n","\n","    generators_saved, this is an iterable list of keras objects that can be used\n","    \n","    discriminators_saved, same thing, these can be used to test\n","\n","    for generator, discriminator in zip(gen, desc):\n","        noise = tf.random.normal(shape=dims)\n","        generated_data = generator(noise)\n","        judgement = discriminator(generated_data) # probs data is real\n","    \"\"\"\n","    generator, discriminator = gan.layers\n","    generators_saved = []\n","    discriminators_saved = []\n","    \n","    for epoch in range(n_epochs):\n","        print(f\"Epoch {epoch} of {n_epochs}\")\n","        if epoch > n_epochs / 4:  # give a 25% training period\n","\n","            generators_saved.append(generator)\n","            discriminators_saved.append(discriminator)\n","            iterations = np.ceil(iterations / 1.1).astype('int') + 10 # after the training period reduce iterations\n","\n","        for _ in tqdm(range(iterations)):\n","            random_index = np.random.permutation(len(dataset))\n","            X_batch = dataset[random_index, :]\n","            # phase 1 - training the discriminator\n","\n","            noise = tf.random.normal(shape=(n_noise, 98),\n","                                     mean=0,\n","                                     stddev=0.1) \n","\n","            generated_data = generator(noise)\n","            X_fake_and_real = tf.concat([generated_data, X_batch], axis=0)\n","\n","            y1 = tf.constant([[0.0]] * noise.shape[0] + [[1.0]] * X_batch.shape[0])\n","            y1 = np.reshape(y1, (len(y1), 1))\n","\n","            discriminator.trainable = True\n","            discriminator.train_on_batch(X_fake_and_real, y1)\n","            # phase 2 - training the generator\n","            y2 = tf.constant([[1.0]] * n_noise)\n","            noise = tf.random.normal(shape=generated_data.shape)\n","            discriminator.trainable = False\n","            gan.train_on_batch(noise, y2)\n","        \n","        noise = tf.random.normal(shape=dims)\n","        generated_data = generator(noise)\n","        judgement = discriminator(generated_data) # probs data is real\n","        print(np.mean(judgement))\n","\n","    return generators_saved, discriminators_saved"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MS9zDiBk7zp2","outputId":"a5a7e3c0-b7eb-4dda-f008-1c5cb5c34f02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 of 100\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████▏    | 5126/10000 [10:10<09:27,  8.58it/s]"]}],"source":["generators_saved, discriminators_saved = train_gan(\n","    gan, df, n_epochs=100, iterations=10000, n_noise=20000\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fJJ4jktVBQwb"},"outputs":[],"source":["import os\n","import re\n","import pickle\n","models = os.listdir(f\"{proj_dir}saved_models/list_of_models/gen\")\n","model_number = [int(re.sub(\"generators\", \"\", x)) for x in models]\n","last_model = max(model_number)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kWlRd-ySASlW"},"outputs":[],"source":["with open(f\"{proj_dir}saved_models/list_of_models/gen/generators{last_model+1}\", \"wb\") as fp:\n","    pickle.dump(generators_saved, fp)\n","\n","with open(f\"{proj_dir}saved_models/list_of_models/disc/discriminators{last_model+1}\", \"wb\") as fp:\n","    pickle.dump(discriminators_saved, fp)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"gan.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}