{"cells":[{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1649622608798,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"hrpAj7PfN8d6","outputId":"31563504-432f-44d2-ee52-faf6e6db5f16"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-8d2d5397-0bb4-fca5-8820-0f076f36f052)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649622609230,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"wHi2BE1wNG3x"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":695,"status":"ok","timestamp":1649622609922,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"vc-vcG2_X-L3","outputId":"e7f09d1e-a068-483c-a2b8-3aabed45dd83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  proj_dir = \"/content/drive/MyDrive/ece884_project/\"\n","else:\n","  proj_dir = \"../\""]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649622609923,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"QUsvJVMA96Lc"},"outputs":[],"source":["import os\n","import re\n","import pickle\n","models = os.listdir(f\"{proj_dir}saved_models/list_of_models/gen\")\n","model_number = [int(re.sub(\"generators\", \"\", x)) for x in models]\n","last_model = max(model_number)"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":4439,"status":"ok","timestamp":1649622614360,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"NcA1lScbtDcF"},"outputs":[],"source":["df = pd.read_csv(f\"{proj_dir}data_clean/taxi.csv\")\n","column_names = df.columns\n","df = df.to_numpy()\n","from sklearn import preprocessing\n","scaler = preprocessing.StandardScaler().fit(df)"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649622614360,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"zPO14qCxNZQY"},"outputs":[],"source":["# TODO lets put this away as a script\n","import tensorflow as tf\n","\n","import numpy as np\n","from tensorflow import keras\n","\n","def build_network(output_dim, n_hidden, n_neurons, learning_rate):\n","\n","    \"\"\"\n","\n","    output_dim: what do we want this to output\n","    Generator output n_columns of data\n","    Discriminator output 1, p(data_real|data_seen)\n","\n","    n_hiden: number of layers of the neural net\n","\n","    n_neurons: number of neuros in the network\n","\n","    learning_rate: duhhh\n","\n","    This outputs a keras neural net\n","    \n","    \"\"\"\n","    model = keras.models.Sequential()\n","    model.add(keras.layers.Flatten())\n","    for _ in range(n_hidden):\n","        model.add(keras.layers.Dense(n_neurons, activation=\"selu\"))\n","        model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Dense(output_dim + 10, activation=\"selu\"))  \n","    model.add(keras.layers.Dense(output_dim, activation=\"sigmoid\"))\n","    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n","    model.compile(optimizer=optimizer)\n","    return model\n","\n","def train_gan(\n","    generator, discriminator, dataset, n_epochs=100, n_noise=20000\n","):\n","    \"\"\"\n","    # TODO: UPDATE ARGS\n","    Inputs: \n","\n","    gan, this is a keras gan object made by combining two neural nets and\n","    restricting the trainability of one of them.\n","\n","    dataset, this takes in regular tabular data. now this is training rowwise\n","    however i may change this to matrix wise like a picture.\n","\n","    n_epochs, numper of times the gans go though training iterationations\n","\n","    iterationations, number of times in gan iterationaton loop, \n","    it would be a good idea to reduct this after the warmup period\n","\n","    n_noise, this is the size of fake data generated\n","\n","    \n","    Output:\n","\n","    generators_saved, this is an iterationable list of keras objects that can be used\n","    \n","    discriminators_saved, same thing, these can be used to test\n","\n","    for generator, discriminator in zip(gen, desc):\n","        noise = tf.random.normal(shape=dims)\n","        generated_data = generator(noise)\n","        judgement = discriminator(generated_data) # probs data is real\n","    \"\"\"\n","    gan = keras.models.Sequential([generator, discriminator])\n","  \n","    discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n","    discriminator.trainable = False\n","    gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n","    generator, discriminator = gan.layers\n","    data_out = np.empty((0, dataset.shape[1]))\n","\n","    \n","    for epoch in range(5):\n","\n","        tf.random.set_seed(epoch*5)\n","        random_index = tf.random.uniform(shape=(n_noise,), minval=0, maxval=len(dataset), dtype=tf.int32)\n","        X_batch = dataset[random_index, :]\n","\n","        for iteration in range(n_noise):\n","\n","            noise = tf.random.normal(shape=X_batch.shape,\n","                                     mean=0,\n","                                     stddev=1) \n","\n","            generated_data = generator(noise)\n","            X_fake_and_real = tf.concat([generated_data, X_batch], axis=0)\n","            y1 = tf.concat([tf.zeros(n_noise), tf.ones(n_noise)], axis=0)\n","            \n","            # training discriminator\n","            discriminator.trainable = True\n","            discriminator.train_on_batch(X_fake_and_real, y1)\n","            # training the generator\n","\n","            noise = tf.random.normal(shape=X_batch.shape,\n","                                     mean=0,\n","                                     stddev=1) \n","            \n","            discriminator.trainable = False\n","            gan.train_on_batch(noise, tf.ones(n_noise))\n","            \n","            # testing quality of model\n","\n","            # TODO:\n","            # Compute Covariance matrix\n","            # Order Stats of generated\n","            # classifier\n","            \n","        noise = tf.random.normal(shape=X_batch.shape,\n","                                  mean=0,\n","                                  stddev=1) \n","        generated_data = generator(noise)\n","        rand = tf.random.uniform(shape=(1,), minval=0, maxval=X_batch.shape[0], dtype=tf.int32)\n","\n","        data_out = np.concatenate([data_out, generated_data[ :5 , :]])\n","    \n","    return data_out\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"VIXppGoR3jkc"},"source":["lets consider initializing a new gan with each epoch or "]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649622614360,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"},"user_tz":240},"id":"iVCVK6wdH8Y4"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"_kPcJEnW1kZn","outputId":"88d2a110-0132-4c54-f2d7-ad591a4de35d","executionInfo":{"status":"error","timestamp":1649622981059,"user_tz":240,"elapsed":366709,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  1%|          | 3/250 [06:06<8:23:08, 122.22s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-c762c9d08908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{proj_dir}data_generated/gan_gen{last_model}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgenerated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-72-d65fe9c3fb1b>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, dataset, n_epochs, n_noise)\u001b[0m\n\u001b[1;32m     97\u001b[0m             noise = tf.random.normal(shape=X_batch.shape,\n\u001b[1;32m     98\u001b[0m                                      \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                      stddev=1) \n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in tqdm(range(500)):\n","\n","    generator = build_network(output_dim=df.shape[1], n_hidden=3, n_neurons=300+i, learning_rate=5e-3 + i * 1e-5)\n","    discriminator = build_network(output_dim=1, n_hidden=2, n_neurons=250+i, learning_rate=1e-3 + i * 1e-5) \n","    gen_data = train_gan(generator, discriminator, df, n_epochs=10, n_noise=1000)\n","    output_path = f\"{proj_dir}data_generated/gan_gen{last_model}.csv\"\n","    generated_data = pd.DataFrame(scaler.inverse_transform(gen_data), columns=column_names) \n","    generated_data.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTL71073q13E","executionInfo":{"status":"aborted","timestamp":1649622981057,"user_tz":240,"elapsed":12,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"}}},"outputs":[],"source":["\n","def generated_data_filter(gen, desc, points_to_gen, threashold, dims):\n","    \"\"\"\n","    inputs\n","    gen, is the list of gans we wrote with the gan.ipynb\n","\n","    desc, is the list of discriminators in the notebook gan.ipynb\n","    \n","    points_to_gen, number of datapoints for each model to generate\n","\n","    threashold, is what is the discriminator's predicted probability of the data being real\n","    we need to see to keep the data. \n","    with a threashold = 0.99 we will drop every datapoint that the discriminator says has a \n","    less than .99 change of being real. \n","    we will need to play with this.\n","\n","    \"\"\"\n","    n_col = dims[1]\n","    quality_data = np.empty((0, n_col), np.float32)\n","\n","    for generator, discriminator in zip(gen, desc):\n","        noise = tf.random.normal(shape=(points_to_gen, n_col))\n","        generated_data = generator(noise)\n","        judgement = discriminator(generated_data) # probs data is real\n","        data_fooling_discriminator = np.compress(np.ravel(judgement) > threashold, generated_data, axis=0)\n","\n","        quality_data = np.append(quality_data, data_fooling_discriminator, axis=0)\n","    \n","    for discriminator in desc:\n","        judgement = discriminator(quality_data)\n","        quality_data = np.compress(np.ravel(judgement) > threashold, quality_data, axis=0)\n","    return quality_data"]},{"cell_type":"code","source":[""],"metadata":{"id":"ScapvoujsghA","executionInfo":{"status":"aborted","timestamp":1649622981058,"user_tz":240,"elapsed":13,"user":{"displayName":"Joe Despres","userId":"11492265170092125564"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"gan.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}